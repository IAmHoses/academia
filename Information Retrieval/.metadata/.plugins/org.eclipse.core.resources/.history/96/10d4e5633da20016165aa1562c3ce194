package dynamic_ranking;

import java.io.BufferedWriter;
import java.io.IOException;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.StandardOpenOption;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.LinkedList;
import java.util.List;
import java.util.Set;

import containers.PositionalPostingList;
import containers.PostingList;
import containers.Query;
import containers.Score;
import containers.Triple;
import tools.ScoreComparator;

public class DynamicPositionalBM25 {
	private HashMap<String, PositionalPostingList> index;
	private Set<String> documents;
	
	private int N;	// number of documents in index
	private HashMap<String, Integer> docLengths;
	private double avgDocLength;
	
	public DynamicPositionalBM25(HashMap<String, PositionalPostingList> _index, Set<String> docs) {
		index = _index;
		documents = docs;
		N = documents.size();
		docLengths = new HashMap<String, Integer>();
		
		compute_docLengths_and_avgDocLength();
		compute_idfs();
	}
	
	public void compute_idfs() {
		for (String term : index.keySet()) {
			PositionalPostingList positionalPostingList = index.get(term);
			positionalPostingList.compute_probabilistic_model_idf(N);;
			index.replace(term, positionalPostingList);
		}
	}
	
	public void compute_docLengths_and_avgDocLength() {
		for (String term: index.keySet()) {
			PositionalPostingList positionalPostingList = index.get(term);
			
			for (String docNo : positionalPostingList.map().keySet()) {
				if (!docLengths.containsKey(docNo)) {
					docLengths.put(docNo, positionalPostingList.map().get(docNo).tf());
				} else {
					docLengths.replace(docNo, docLengths.get(docNo) + positionalPostingList.map().get(docNo).tf());
				}
			}
		}
		int docLengthSum = 0;
		
		for (String docNo : docLengths.keySet()) {
			docLengthSum += docLengths.get(docNo);
		}
		avgDocLength = docLengthSum / docLengths.size();
	}
	
//	public void generateBM25Output(Query query) {
//		LinkedList<String> twoGrams = generateTwoGrams(query.string().split(" "), query.number());
//		System.out.println("Two-grams for query number: " + query.number());
//		for (String twoGram : twoGrams) {
//			System.out.println(twoGram);
//		}
////		generateBM25Output(1.2, 500, 0.75);
//	}
//	
	
	public String generateBM25Output(Query query, double k_1, int k_2, double b) {
		String output = "";
		
		Score[] scores = new Score[N];
		int i = 0;
		
		for (String docNo : documents) {
			double score = 0;
			
			LinkedList<String> twoGrams = generateTwoGrams(query.string().split(" "));
			for (String twoGram : twoGrams) {
				System.out.println(twoGram);
				
				if (!index.containsKey(splitGram[0]) || !index.containsKey(splitGram[1])) {
					continue;
				}
				
				int tf_ij = compute_positional_tf(docNo, twoGram);
				
				double w = index.get(twoGram.split(" ")[0]).idf() + index.get(twoGram.split(" ")[1]).idf();
				double term2_numerator = (k_1 + 1) * tf_ij;
				double term2_denominator = (tf_ij + (k_1 * (1 - b + (b * (docLengths.get(docNo) / avgDocLength)))));
				double term3 = ((k_2 + 1) * 1) / (k_2 + 1);
				
				score += w * (term2_numerator / term2_denominator) * term3;
			}	
			
			if (String.valueOf(score)!= "NaN" && score != 0) {
				scores[i] = new Score(score, query.number(), docNo);
				i++;
			}
		}
	    List<Score> list = new ArrayList<Score>(Arrays.asList(scores));
	    list.removeAll(Collections.singleton(null));
	    scores = list.toArray(new Score[list.size()]);
		
		Arrays.sort(scores, new ScoreComparator());
		
		int indexUpperLimit;
		
		if (scores.length > 100) {
			indexUpperLimit = 100;
		} else {
			indexUpperLimit = scores.length;
		}
		
		for (int j = 0; j < indexUpperLimit; j++) {
			output += scores[j].queryNumber() + " 0 " + scores[j].documentNumber() + " " + (j+1) + " " + scores[j].score() + " BM25\n";
		}
		
		return output;
		
		// NOW WRITE THAT SHIT :D
		
//		Path path = Paths.get("Results/staticBM25.txt");
//		try {
//			BufferedWriter bw = Files.newBufferedWriter(path, StandardOpenOption.CREATE);
//			bw.write(output);
//			bw.close();
//		} catch (IOException e) {
//			// TODO Auto-generated catch block
//			e.printStackTrace();
//		}
	}
	
	public LinkedList<String> generateTwoGrams(String[] tokens) {
		String[] zipper1 = new String[tokens.length + 1];
		String[] zipper2 = new String[tokens.length + 1];
		
		for (int i = 0; i < tokens.length; i++) {
			zipper1[i + 1] = tokens[i];
			zipper2[i] = tokens[i];
		}

		String[] raw_twoGrams = new String[tokens.length + 1];
		
		for (int j = 0; j < raw_twoGrams.length; j++) {
			if (zipper1[j] == null || zipper2[j] == null) {
				continue;
			}
			raw_twoGrams[j] = zipper1[j] + "_" + zipper2[j];
		}
		
	    List<String> list = new ArrayList<String>(Arrays.asList(raw_twoGrams));
	    list.removeAll(Collections.singleton(null));
	    raw_twoGrams = list.toArray(new String[list.size()]);
		
	    LinkedList<String> twoGrams = new LinkedList<String>();
		
		for (String twoGram : raw_twoGrams) {
			String[] splitGram = twoGram.trim().split("\\_");
			
			if (twoGram == null || splitGram.length < 2) {
				continue;
			}
			twoGrams.add(twoGram);
		}
		
		return twoGrams;
	}
	
	public int compute_positional_tf(String docNo, String twoGram) {
		String[] splitGram = twoGram.split(" ");
		
		PositionalPostingList list1 = index.get(splitGram[0]);	// grab posting list for current query token
		PositionalPostingList list2 = index.get(splitGram[1]);	// grab posting list for current query token
		
		if (!list1.map().containsKey(docNo) || !list1.map().containsKey(docNo)) {	// posting list for token has a mapping for the document in question
			return 0;
		}
		
		int tf = 0;
		
		for (int position1 : list1.map().get(docNo).positions()) {
			for (int position2 : list2.map().get(docNo).positions()) {
				if (Math.abs(position1 - position2) == 1) {
					tf++;
				}
			}
		}
		
		System.out.println("tf for " + twoGram + ": " + tf);
		
		return tf;
	}
}
